% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SelectionScore.R
\name{SelectionScore}
\alias{SelectionScore}
\title{Selection probabilities of the regularization model using the elastic-net penalty with multiresponse gaussian family (MNET).}
\usage{
SelectionScore(
  x,
  y,
  family,
  seq.alpha = NULL,
  seq.lambda = NULL,
  delta = 1,
  compare = TRUE,
  K = 100,
  psub = 1,
  penalty.factor = NULL,
  standardize.response = TRUE,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{x}{An \code{n} by \code{p} matrix of high-dimensional genomic data such as gene expression or single nucleotide polymorphism (SNP) data.}

\item{y}{An \code{n} by \code{q} matrix of phenotypic outcomes, each with being either continuous or categorical.}

\item{family}{A vector of distribution family, such as 'gaussian', 'binomial', 'multinomial', etc.}

\item{seq.alpha}{A grid vector of the mixing proportion used in elastic-net penalty. Default is c(0.1, ..., 0.9).}

\item{seq.lambda}{A grid vector of the penalty parameter used in elastic-net penalty. It can be provided through our function 'grid.lambda'.}

\item{delta}{Denoising parameter ranged between 0 and 1. If \code{delta} = 1, each selection result will be tuned to have the same selection counts that is equal to the minimum of selection counts over phenotypes without any denoising process. If \code{delta} < 1, the selection counts is reduced to \code{delta} * minimum of selection counts over phenotypes.}

\item{K}{The number of resampling replicates when calculating the selection probability. Default is 100.}

\item{psub}{The subsampling proportion which reduces the computational costs efficiently. Default is 1.0 with replacement. If \code{psub} < 1.0, then resampling will be performed without replacement.}

\item{penalty.factor}{A vector of penalty to be imposed for each column of x. The 0 value indicates no penalty which leads the variable always to be included in the model. On the other hand, the 1 value indicates that the penalty is imposed for each column as it was.}

\item{standardize.response}{If TRUE, each phenotype is scaled to have zero mean and unit variance.}

\item{verbose}{If TRUE, some information for the calculation process will be printed.}
}
\value{
A data.frame with each column representing the selection probability for each phenotype
}
\description{
The penalized regression model using elastic-net penalty with multiresponse gaussian family (MNET) aims to solve the following problem:
\deqn{ \frac{1}{2} \| Y - X \beta \|_F^2 +  \lambda [ \frac{1-\alpha}{2} ||\beta||_F^2 + \alpha \sum_{j=1}^p ||\beta_j||_2 ]}
}
\examples{
# library(mnormt)
library(mnormt)
library(glmnet)
library(dplyr)

for( i in list.files("./R") \%>\% {.[!.\%in\%"unet-package.R"]} ){
  source(paste0("./R/", i))
}

set.seed(1)
n=100; p=1000; q=4

X <- replicate(p, rbinom(n,2,0.2)) #generate the SNP X=0,1,2
b <- matrix(0, p, q)
b[1:5,1:4] <- 1.0
b[6:10,1:2] <- 1.0


Z <- replicate(1, rnorm(n))
g <- matrix(0, 1, q)
g[1,1:4] <- 0.1

x <- cbind(Z, X)
beta <- rbind(g, b)

y <- x\%*\%beta + replicate(q, rnorm(n,1))
y[,2:3] <- apply(y[,2:3], 2, function(yk) ifelse(yk > median(yk), 1, 0) )
Family<-c("gaussian","binomial","binomial","gaussian")
alpha.vec <- 0.1
penalty.factor <- c(0, rep(1, p))

lambda.vec.enet <- grid.lambda(x = x, y = y,
                               family = Family,
                               method = "enet",
                               iter = 10,
                               seq.alpha = 0.1, n.lambda = 10,
                               penalty.factor=penalty.factor) \%>\%
  lapply( function(x) seq(median(x), max(x), length.out=10) )


SelectionScore(x, y, Family, seq.alpha = 0.1, seq.lambda = lambda.vec.enet, delta = 1, K = 100, psub = 1.0, penalty.factor = penalty.factor, verbose = TRUE)



set.seed(1)
sp.total2 <- main( x = cbind(Z,X), y = Y,
family = Family,
method = c("unet_df"),
seq.alpha = alpha.vec,
seq.lambda = list(enet=NULL,
mnet=NULL),
seq.df = df.vec,
K = 10,
penalty.factor = penalty.factor )

set.seed(1)
res.threshold2 <- threshold(sp.total2$params, nperm=10)





}
\references{
Zou, H., & Hastie, T. (2005). Regularization and variable selection via the elastic net. Journal of the royal statistical society: series B (statistical methodology), 67(2), 301-320.
Meinshausen, N., & BÃ¼hlmann, P. (2010). Stability selection. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 72(4), 417-473.
Simon, N., Friedman, J., & Hastie, T. (2013). A blockwise descent algorithm for group-penalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529.
Kim, K., Koo, J., & Sun, H. (2020). An empirical threshold of selection probability for analysis of high-dimensional correlated data. Journal of Statistical Computation and Simulation, 1-12.
}
\author{
Kipoong Kim \href{mailto:kkp7700@gmail.com}{kkp7700@gmail.com}
}
